---
title: "As Principais Diretrizes do Google para Inteligência Artificial"
seoTitle: "Diretrizes Essenciais para IA do Google"
seoDescription: "Descubra os 7 princípios do Google para uma inteligência artificial ética e responsável, promovendo benefícios sociais, equidade e segurança"
datePublished: Sun Dec 01 2024 03:00:00 GMT+0000 (Coordinated Universal Time)
cuid: cm7bpo7c2000509l5c3lt67w0
slug: as-sete-diretrizes-para-uma-ia-do-google
cover: https://cdn.hashnode.com/res/hashnode/image/upload/v1739956213903/2c6beeb5-c0bc-44ac-bd8f-5f60367790c6.jpeg
ogImage: https://cdn.hashnode.com/res/hashnode/image/upload/v1739957295845/83893bd7-e41e-4dee-afbf-a7b689679a6c.jpeg

---

---

[*Leia também em inglês aqui.*](https://gustavosantosio.com/key-guidelines-from-google-on-artificial-intelligence-explained)

Em 2018, o Google, percebendo a crescente importância e o potencial impacto da Inteligência Artificial (IA) na sociedade, e reconhecendo a necessidade de ter diretrizes claras para seu desenvolvimento e uso, definiu um conjunto de 7 princípios fundamentais para orientar a criação de uma IA responsável.

Esses princípios abrangem uma ampla gama de considerações éticas e sociais, buscando garantir que a IA seja desenvolvida e utilizada de maneira a beneficiar a humanidade, minimizando riscos e promovendo a equidade e a justiça.

## Os sete princípios

1. **Benefício Social:** A IA deve ser desenvolvida para beneficiar a sociedade como um todo, considerando os impactos e garantindo que as vantagens sejam amplamente distribuídas.
    
2. **Evitar Vieses Injustos:** A IA não deve perpetuar ou criar preconceitos baseados em características como raça, gênero, religião ou orientação sexual. É crucial garantir que os sistemas de IA sejam justos e imparciais.
    
3. **Segurança:** A IA deve ser desenvolvida e testada rigorosamente para garantir sua segurança, minimizando riscos e prevenindo danos.
    
4. **Responsabilidade:** Os sistemas de IA devem ser transparentes e explicáveis, permitindo que as pessoas entendam como as decisões são tomadas e possam contestá-las se necessário.
    
5. **Privacidade:** A IA deve respeitar a privacidade dos usuários, protegendo seus dados e fornecendo controle sobre como as informações são utilizadas.
    
6. **Excelência Científica:** A IA deve ser baseada em pesquisa científica de alta qualidade, promovendo o avanço do conhecimento e garantindo que os sistemas sejam confiáveis e eficazes.
    
7. **Disponibilidade para Usos Responsáveis:** A IA deve ser utilizada apenas para fins que estejam alinhados com esses princípios, evitando aplicações que possam ser prejudiciais ou abusivas.
    

![Imagem utilizada durante a apresentação no Google I/O 2024.](https://cdn.hashnode.com/res/hashnode/image/upload/v1739956598315/76f84b40-f2f5-4808-a328-0eeebcdc25c5.png align="center")

---

## **Áreas Proibidas para a IA**

O Google estabeleceu uma série de áreas em que a utilização da Inteligência Artificial (IA) é estritamente proibida, com o objetivo de prevenir potenciais danos e assegurar o uso ético e responsável da tecnologia. Estas áreas são complementares aos 7 princípios éticos da IA do Google e incluem:

1. **Desenvolvimento de tecnologias com potencial de causar danos generalizados:**
    

Esta proibição inclui qualquer IA que possa ser utilizada para criar armas de destruição em massa, sistemas de vigilância opressivos, ou outras tecnologias que possam causar danos significativos a um grande número de pessoas. O Google compromete-se a não desenvolver IA que possa ser utilizada para fins maliciosos ou que possa ter consequências catastróficas.

2. **Criação de armas ou outros meios de ferir pessoas:**
    

O Google proíbe explicitamente o uso da sua IA para o desenvolvimento de armas autónomas, armas químicas ou biológicas, ou qualquer outra tecnologia que tenha como objetivo principal ferir ou matar pessoas. Esta proibição inclui a utilização da IA para melhorar a precisão ou eficácia de armas existentes, bem como o desenvolvimento de novos tipos de armas que utilizem IA.

3. **Utilização de informações que violem normas de privacidade internacionalmente aceitas:**
    

A IA do Google não deve ser utilizada para coletar, armazenar ou processar informações pessoais de forma que viole as leis de privacidade ou os direitos humanos. Esta proibição inclui a utilização da IA para vigilância em massa, discriminação com base em dados pessoais, ou qualquer outra atividade que possa comprometer a privacidade das pessoas.

4. **Desenvolvimento de tecnologias que violem direitos humanos ou o direito internacional:**
    

O Google compromete-se a não utilizar a IA para desenvolver tecnologias que possam ser utilizadas para violar os direitos humanos, como a liberdade de expressão, o direito à privacidade, ou o direito à vida. Esta proibição inclui a utilização da IA para censura, discriminação, ou qualquer outra atividade que possa negar às pessoas os seus direitos fundamentais.

---

**Além destas áreas proibidas, o Google também se compromete a:**

* **Implementar salvaguardas:** O Google implementará salvaguardas técnicas e processuais para garantir que a sua IA não seja utilizada para fins proibidos.
    
* **Monitorizar o uso da IA:** O Google monitorizará ativamente o uso da sua IA para identificar e prevenir potenciais abusos.
    
* **Cooperar com outras organizações:** O Google cooperará com outras organizações e governos para promover o uso ético e responsável da IA.
    

**Ao estabelecer estas áreas proibidas e adotar um compromisso com o uso responsável da IA, o Google visa garantir que esta poderosa tecnologia seja utilizada para o benefício da humanidade, e não para o seu detrimento.**

---

## **Evolução e Atualizações Recentes**

Em fevereiro de 2025, o Google revisou seus princípios originais de 2018, mantendo o compromisso ético central mas alterando abordagens estratégicas. As mudanças refletem:

1. **Foco em análise de risco-benefício**  
    Substituiu proibições categóricas por avaliações onde "benefícios substanciais devem superar riscos previsíveis". Isso permite parcerias com governos para usos militares defensivos e segurança nacional, desde que alinhados ao direito internacional.
    
2. **Três pilares estratégicos**
    
    * Inovação ousada (impulsionar avanços científicos)
        
    * Desenvolvimento responsável (monitoramento contínuo de vieses e segurança)
        
    * Colaboração multissetorial (padrões globais com governos e academia)
        
3. **Novas salvaguardas técnicas**
    
    * Sistemas de rastreamento de *deepfakes* com marcas d'água digitais
        
    * Filtros aprimorados contra *phishing* automatizado via IA generativa
        

**Críticas e Controvérsias**  
A remoção explícita da proibição de "IA para armas" gerou debates na comunidade técnica. Especialistas apontam que o novo critério de "benefícios superarem riscos" permite interpretações flexíveis para contratos militares. Entretanto, o Google mantém proibições específicas em sua política de IA generativa contra:

* Conteúdo íntimo não consensual
    
* Engenharia social maliciosa
    
* Geração de *malware*
    

**Impacto Global**  
O modelo atualizado prioriza:

* Alinhamento com legislações nacionais emergentes
    
* Parcerias para segurança cibernética
    
* Pesquisa em IA para saúde e sustentabilidade
    

Essas mudanças refletem o duplo desafio de manter liderança tecnológica enquanto navega em complexidades geopolíticas. O documento completo está disponível em [AI.Google](http://ai.google/responsibility/principles/).

---

## Fontes:

1. [http://ai.google/responsibility/principles/](http://ai.google/responsibility/principles/)
    
2. [https://blog.google/technology/ai/responsible-ai-2024-report-ongoing-work/](https://blog.google/technology/ai/responsible-ai-2024-report-ongoing-work/)
    
3. [https://ppc.land/google-updates-prohibited-use-policy-for-generative-ai-with-clearer-guidelines/](https://ppc.land/google-updates-prohibited-use-policy-for-generative-ai-with-clearer-guidelines/)
    
4. [https://ai.google/static/documents/ai-principles-2020-progress-update.pdf](https://ai.google/static/documents/ai-principles-2020-progress-update.pdf)
    
5. [https://blog.google/technology/ai/ai-principles/](https://blog.google/technology/ai/ai-principles/)
    
6. [https://ai.google/static/documents/ai-principles-2021-progress-update.pdf](https://ai.google/static/documents/ai-principles-2021-progress-update.pdf)
    
7. [https://ai.google/responsibility/principles/](https://ai.google/responsibility/principles/)
    
8. [https://policies.google.com/terms/generative-ai/use-policy](https://policies.google.com/terms/generative-ai/use-policy)
    
9. [https://ai.google/static/documents/ai-principles-2022-progress-update.pdf](https://ai.google/static/documents/ai-principles-2022-progress-update.pdf)
    
10. [https://www.washingtonpost.com/technology/2025/02/04/google-ai-policies-weapons-harm/](https://www.washingtonpost.com/technology/2025/02/04/google-ai-policies-weapons-harm/)
    
11. [https://blog.google/feed/were-updating-our-generative-ai-prohibited-use-policy/](https://blog.google/feed/were-updating-our-generative-ai-prohibited-use-policy/)
    
12. [https://ai.google/static/documents/EN-AI-Principles.pdf](https://ai.google/static/documents/EN-AI-Principles.pdf)
    
13. [https://cloud.google.com/transform/ai-expectations-2025-hundreds-of-google-cloud-customers](https://cloud.google.com/transform/ai-expectations-2025-hundreds-of-google-cloud-customers)
    

---