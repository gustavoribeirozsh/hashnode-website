---
title: "Aplicações de Inteligência Artificial em Produção no Microsoft Azure com Terraform, Observabilidade, OpenTelemetry e Ingestão de Dados"
seoTitle: "IA na Produção: Azure, Terraform e OpenTelemetry"
seoDescription: "IA no Azure com Terraform, OpenTelemetry e MLOps: segurança, governança, otimização"
datePublished: Mon Oct 27 2025 16:55:28 GMT+0000 (Coordinated Universal Time)
cuid: cmh9dpgy7000202jx0dus9eej
slug: aplicacoes-de-inteligencia-artificial-em-producao-no-microsoft-azure-com-terraform-observabilidade-opentelemetry-e-ingestao-de-dados
cover: https://cdn.hashnode.com/res/hashnode/image/upload/v1761583986261/19727db2-d016-4456-bc01-76453410ec5d.png
ogImage: https://cdn.hashnode.com/res/hashnode/image/upload/v1761584100224/a02e85cd-ebff-469b-bdfd-7ab40cc04bde.png
tags: ai, azure, data-science, developer, cloud-computing, devops, sre, terraform, iac, opentelemetry, iammfaaccess-key-idsecret-access-key, ai-tools

---

---

### **Introdução à Arquitetura MLOps e o Papel do Terraform**

A implementação bem-sucedida de aplicações de Inteligência Artificial (IA) em ambientes de produção de larga escala exige a adoção de princípios de Machine Learning Operations (MLOps). Central a esta abordagem é a Infraestrutura como Código (IaC), onde o Terraform se estabelece como a ferramenta ideal para definir, provisionar e gerenciar a infraestrutura do Azure de forma repetível e previsível.

Ao utilizar arquivos de configuração declarativos, o Terraform garante que a infraestrutura subjacente (rede, computação, armazenamento e observabilidade) seja tratada como código, permitindo que a equipe de engenharia trate a arquitetura do ambiente de ML como um recurso versionável e auditável.

A *stack* tecnológica recomendada para uma aplicação de IA moderna no Azure tipicamente inclui o Azure Machine Learning (AML) como plataforma central de IA, o Azure Container Apps (ACA) para o serviço de inferência *serverless*, e mecanismos de ingestão de dados como Azure Data Factory (ADF) ou Azure Event Hubs. A unificação da gestão desses componentes críticos via Terraform é a espinha dorsal desta arquitetura MLOps.

**Princípios de Governança e Gerenciamento de Estado Remoto**

O arquivo de estado do Terraform (tfstate) é um componente altamente sensível, pois contém o mapeamento de todos os recursos provisionados e, potencialmente, dados confidenciais (como IDs de recursos e FQDNs). Por essa razão, ele jamais deve ser armazenado localmente. O gerenciamento seguro exige o uso do *backend* azurerm, que armazena o estado como um *Blob* em um Azure Storage Account, garantindo bloqueio de estado e verificação de consistência.

Para produção, a autenticação ao *data plane* da conta de armazenamento deve ser rigorosamente controlada. O método recomendado é o uso de **Azure Active Directory (AAD)** ou **Managed Identity (MI)**, afastando-se do uso de Access Keys estáticas ou Tokens SAS. A dependência de chaves estáticas representa uma vulnerabilidade significativa, pois essas chaves, se comprometidas, podem expor o estado do Terraform a ataques. Ao configurar o *backend* para autenticação via MI (especialmente com OpenID Connect/Workload Identity Federation), o acesso é delegado e gerenciado pela Azure, concedendo credenciais temporárias ao *runner* de CI/CD, minimizando drasticamente a superfície de ataque e aderindo ao Princípio do Privilégio Mínimo (PoLP).

### **Estrutura Modular e Reutilização (MLOps Component-Based)**

Para suportar múltiplos ambientes (como desenvolvimento, teste e produção) e promover a reutilização, o projeto Terraform deve seguir uma estrutura modular clara. As diretrizes de engenharia de software recomendam a separação lógica em módulos reutilizáveis (modules/) e configurações de ambiente raiz (environments/dev, environments/prod).

Cada componente lógico da infraestrutura deve ser encapsulado em seu próprio módulo. Por exemplo, um módulo ml\_platform pode ser criado para provisionar o Azure ML Workspace, o Application Insights e as contas de armazenamento associadas.3 O diretório raiz de cada ambiente (environments/prod) então invoca este módulo, passando apenas as variáveis específicas daquele ambiente (ex: SKUs, nomes de recursos, restrições de rede).3

Dentro de cada módulo, a consistência é vital. Recomenda-se o uso de arquivos como [main.tf](http://main.tf), [variables.tf](http://variables.tf), e [outputs.tf](http://outputs.tf). Variáveis e saídas devem incluir descrições detalhadas, e as saídas, como storage\_primary\_connection\_string, devem seguir um padrão descritivo ({nome}\_{atributo}) para serem compreensíveis fora do escopo do módulo.

**Estratégia Monstra: IaC, MLOps e Azure de Base**

* **MLOps e Terraform:** Pra IA em larga escala, MLOps é essencial. O Terraform entra como o parceiro ideal pra gerenciar toda a infraestrutura do Azure (rede, computação, armazenamento, observabilidade) como código. Assim, dá pra versionar e auditar tudo!
    
* **Stack Tecnológica:** Geralmente, usamos Azure Machine Learning (AML) pra IA, Azure Container Apps (ACA) pra inferência serverless e Azure Data Factory (ADF) ou Azure Event Hubs pra ingestão de dados. O Terraform unifica tudo isso!
    
* **Governança e Estado Remoto:** O arquivo de estado do Terraform (tfstate) é super sensível. Nada de guardar localmente! Use o backend azurerm, que joga o estado num Azure Storage Account, com bloqueio e checagem de consistência.
    
* **Autenticação Segura:** Pra produção, a autenticação deve ser via Azure Active Directory (AAD) ou Managed Identity (MI). Esqueça Access Keys estáticas ou Tokens SAS, que são furada! MI com OpenID Connect/Workload Identity Federation é o caminho.
    
* **Estrutura Modular:** Pra organizar a casa, separe tudo em módulos reutilizáveis (modules/) e configs de ambiente (environments/dev, environments/prod). Cada pedaço da infra vira um módulo (ex: ml\_platform pro Azure ML Workspace).
    
* **Consistência nos Módulos:** Dentro dos módulos, use [main.tf](http://main.tf), [variables.tf](http://variables.tf) e [outputs.tf](http://outputs.tf). Descreva bem as variáveis e saídas, e siga um padrão pra elas (ex: storage\_primary\_connection\_string).
    

**Governança e Conformidade com Código (Policy as Code)**

* **Tagging pra Gastos:** Pra controlar a grana e ver tudo no Azure, use tags (ex: env:production).
    
* **Forçando Tags:** Implemente Policy as Code (PaC) com azurerm\_policy\_definition pra obrigar a presença de tags importantes em todos os recursos. Em produção, use o efeito "Deny" pra barrar recursos sem tag.
    
* **Otimização de Custos:** Pense em custo desde o início! Right-sizing é a chave. ACA já faz autoscaling pra inferência.
    
* **Reservas de Capacidade:** Pra workloads pesados (clusters de GPU no Azure ML), use Reserved Instances (RIs) ou Capacity Reservations (azurerm\_capacity\_reservation) pra economizar uma grana.
    

**Rede Segura pra IA (Zero Trust)**

* **Design da VNet:** Defina a Virtual Network (VNet) e suas sub-redes com Terraform. Sub-redes dedicadas pra Azure ML Workspace, Azure Container Apps Environment e Private Endpoints.
    
* **Private Link e Private DNS Zones:** Pra "Zero Trust", tudo acessa via rede privada. Use Terraform pra provisionar Private Endpoints (azurerm\_private\_endpoint) pra recursos críticos (Azure ML Workspace, Storage, Key Vault, ADF/Event Hubs).
    
* **Resolução de Nomes:** Configure Private DNS Zones (ex: [privatelink.azureml.net](http://privatelink.azureml.net)) e associe-as à VNet com azurerm\_private\_dns\_zone\_virtual\_network\_link.
    
* **Identidade e Acesso (RBAC & Managed Identity):** Rede é bom, mas controle de identidade é essencial. Managed Identities (MI) são o método preferencial pra comunicação segura entre serviços.
    
* **RBAC com Terraform:** O Terraform define as permissões (Role-Based Access Control - RBAC) que as MIs precisam (azurerm\_role\_assignment). Ex: MI do Azure ML Compute Cluster precisa de "Storage Blob Data Contributor" na conta de armazenamento.
    
* **Segurança Combinada:** Private Endpoint + MI com RBAC adequado = segurança de verdade!
    

**Provisionando a Plataforma de IA (Azure Machine Learning)**

* **Azure ML Workspace / AI Hub com AVM:** O Azure ML Workspace é o coração do ciclo de vida do ML. Use o Azure Verified Module (AVM) Azure/avm-res-machinelearningservices-workspace pra provisionar o Workspace e suas dependências (Key Vault, Storage Account, Application Insights).
    
* **Kind do Workspace:** O parâmetro kind permite criar um Workspace padrão, um **AI Hub** (pra IA Generativa) ou um **AI Project**. Pra GenAI, AI Hub é a pedida.
    
* **Segurança do Workspace:** Configure o módulo pra desativar o acesso público e integrar o Private Endpoint.
    
* **Compute Clusters:** Pra treinamento e processamento de dados, use clusters de computação dedicados (azurerm\_machine\_learning\_compute\_cluster).
    
* **MI para Clusters:** Configure a Managed Identity do Compute Cluster pra ter as permissões necessárias (via azurerm\_role\_assignment) pra acessar os Azure Storage Accounts.
    

**Ingestão de Dados Segura com Terraform (Data Ingestion as Code)**

* **ADF pra Batch:** Pra processamento em lote, use Azure Data Factory (ADF) (azurerm\_data\_factory).
    
* **Linked Services com MI:** Configure os Linked Services com Managed Identity (use\_managed\_identity = true) pra não usar connection strings sensíveis.
    
* **Pipelines e Datasets:** O Terraform também provisiona os pipelines (azurerm\_data\_factory\_pipeline) e datasets.
    
* **Event Hubs pra Streaming:** Pra streaming em tempo real, Azure Event Hubs é a boa. Terraform provisiona o Namespace e as instâncias de Event Hub.
    
* **Segurança Consistente:** Se o Azure ML acessa Storage via Private Endpoint, o pipeline de ingestão (ADF ou Event Hubs) também tem que usar MI e Private Endpoint pra acessar o mesmo Storage.
    

**Deployment de Inferência em Produção com Azure Container Apps (ACA)**

* **Por que ACA?** Azure Container Apps (ACA) é a plataforma serverless top pra hospedar APIs de inferência de modelos de IA. Facilita o deployment e escalabilidade.
    
* **Provisionamento do ACA e Autoscaling:** O Terraform gerencia o ACA App (azurerm\_container\_app) e o Environment. Configure o autoscaling no bloco template com base em HTTP ou outros triggers.
    
* **Variáveis de Ambiente e Segredos:** Credenciais sensíveis (tokens, chaves de API) devem ser injetadas como segredos no ACA (secret block) e referenciadas no bloco env.
    
* **Observabilidade:** A connection string do Application Insights vai como segredo na variável **APPLICATIONINSIGHTS\_CONNECTION\_STRING.**
    

**Observabilidade End-to-End com OpenTelemetry**

* **Application Insights:** O Terraform provisiona o Application Insights (azurerm\_application\_insights) pra coletar logs, métricas e traces. Idealmente, dentro do módulo ml\_platform.
    
* **Connection String:** A connection string do Application Insights deve ser uma saída do módulo e injetada no módulo do ACA como variável de ambiente.
    
* **Instrumentação com OpenTelemetry:** Use OpenTelemetry (Otel) como padrão. A **Azure Monitor OpenTelemetry Distro** é a preferida pra Python, .NET ou Java.
    
* **Configuração Minimalista:** No código, chame configure\_azure\_monitor() no startup, usando a connection string do ambiente.
    
* **IaC e Contexto de Telemetria:** O Terraform injeta a connection string e variáveis de ambiente (como Cloud Role Name - ex: ML-Inference-API-Prod) pra contextualizar a telemetria no Application Map do Azure Monitor.
    

**VIII. Síntese e Conclusão: MLOps Turbinado pelo IaC**

* **Ciclo de Vida MLOps Validado:** A estrutura modular do Terraform (modules/ e environments/) garante que as configs de produção e desenvolvimento sejam consistentes. O Terraform é o motor do MLOps.
    
* **Auditoria de Segurança (Checklist IaC):** A segurança vem de vários controles declarados no Terraform:
    
    1. **Gerenciamento de Estado:** Acesso ao tfstate só com AAD ou MI.
        
    2. **Perímetro de Rede:** Todos os serviços críticos protegidos por Private Endpoints.
        
    3. **Controle de Identidade:** Comunicação service-to-service com Managed Identity e RBAC.
        
    4. **Ingestão de Dados:** Linked Services do ADF com autenticação Managed Identity.
        
    5. **Governança:** Conformidade de tagging com Azure Policy (efeito Deny).
        
* **Próximos Passos:** Expandir o IaC pra gerenciar pipelines de treinamento no Azure ML, automatizar o Registro de Modelos e monitorar custos pra otimizar o redimensionamento de recursos.
    

É isso! Com Terraform, sua IA no Azure fica no esquema, segura e otimizada!

---

## **Fundação de Rede Segura para Workloads de IA (Zero Trust)**

### *Design da VNet e Sub-Redes*

A segurança de aplicações de IA começa na rede. O Terraform deve definir a VNet e sub-redes dedicadas para Azure ML Workspace, Azure Container Apps Environment e Private Endpoints.

### **Implementação de Private Link e Private DNS Zones**

Para Zero Trust, todos os serviços de IA e dados devem ser acessados via rede privada. O Terraform provisiona Private Endpoints (azurerm\_private\_endpoint) para proteger Azure ML Workspace, Azure Storage, Azure Key Vault e serviços de ingestão. Private DNS Zones (ex: [privatelink.azureml.net](http://privatelink.azureml.net)) são configuradas e associadas à VNet.

**Gestão de Identidade e Acesso (RBAC & Managed Identity)**

A segurança de rede é complementada por controle de identidade. Managed Identities (MI) são preferenciais para comunicação service-to-service. O Terraform define atribuições de função (RBAC) via azurerm\_role\_assignment para que as MIs acessem recursos, como a MI do Azure ML Compute Cluster acessando o Storage Account. A identidade e a rede devem trabalhar juntas para mitigar falhas de segurança.

### **Provisionamento da Plataforma de IA (Azure Machine Learning)**

O Azure Machine Learning Workspace é central para o ML. Recomenda-se o Azure Verified Module (AVM) Azure/avm-res-machinelearningservices-workspace, que provisiona o Workspace e suas dependências (Key Vault, Storage Account, Application Insights). O parâmetro 'kind' permite provisionar um AI Hub para GenAI. O módulo deve desativar o acesso público e integrar o Private Endpoint.

## **Compute Clusters para o Ciclo de Vida do ML**

Clusters de computação são necessários para o ciclo de vida do ML. O Terraform cria o azurerm\_machine\_learning\_compute\_cluster e configura sua identidade gerenciada (MI) com as atribuições de função (azurerm\_role\_assignment) necessárias para acessar Storage Accounts protegidos por Private Endpoint.

## **Ingestão de Dados na Fonte com Terraform (Data Ingestion as Code)**

O IaC deve estender-se à ingestão de dados, garantindo segurança e repetibilidade.

### **Pipeline de Dados Batch com Azure Data Factory (ADF)**

Para processamento em lote, o Azure Data Factory (ADF) é padrão. O Terraform provisiona o azurerm\_data\_factory e configura Linked Services com Managed Identity (use\_managed\_identity = true), eliminando credenciais sensíveis. Pipelines e datasets também são provisionados.

### **Ingestão de Streaming com Azure Event Hubs**

Para streaming, o Azure Event Hubs é a solução. O Terraform provisiona o Namespace e as instâncias de Event Hub. O Namespace deve ser integrado à VNet via Private Link, e políticas de acesso devem seguir o princípio de mínimo privilégio. O pipeline de ingestão deve manter a consistência da segurança de rede com a plataforma de IA, utilizando Managed Identity e Private Endpoint para acessar o Storage Account.

## **Deployment de Inferência em Produção com Azure Container Apps (ACA)**

O Azure Container Apps (ACA) é a plataforma serverless recomendada para APIs de inferência de IA, simplificando deployment e escalabilidade, com suporte a contêineres e GPUs. O Terraform gerencia o ACA App e o Environment.

## **Provisionamento do ACA e Configuração de Autoscaling**

**O deployment de inferência começa com o provisionamento do ACA Environment, integrado à VNet.** O **azurerm\_container\_app** define a imagem, modo de revisão e regras de autoscaling baseadas em HTTP ou outros triggers.

## **Injeção Segura de Variáveis de Ambiente e Segredos**

Credenciais sensíveis são injetadas como segredos (**azurerm\_container\_app blocks secret**) e referenciadas no bloco 'env' do contêiner. A connection string do Application Insights, por exemplo, é injetada como **APPLICATIONINSIGHTS\_CONNECTION\_STRING**.

### **Implementando Observabilidade End-to-End com OpenTelemetry**

*Provisionamento e Conexão do Application Insights*

O Terraform provisiona o azurerm\_application\_insights como sink de telemetria, preferencialmente no módulo ml\_platform. A connection string é exposta como output e consumida pelo módulo ACA para injeção segura de variáveis de ambiente.

**Estratégia de Instrumentação de Código-Fonte (OpenTelemetry)**

A instrumentação foca no OpenTelemetry (Otel) com a Azure Monitor OpenTelemetry Distro para coletar traces, métricas e logs. A função configure\_azure\_monitor() é chamada na inicialização da aplicação com a connection string.

**Conexão IaC e Contexto de Telemetria**

O Terraform sincroniza a infraestrutura de observabilidade e a aplicação de inferência, injetando a connection string e variáveis de ambiente (Cloud Role Name, Cloud Role Instance) para definir o contexto da telemetria, facilitando diagnósticos.

| **Componente (Deployment)** | **Recurso Azure** | **Tipo de Telemetria (OpenTelemetry)** | **Configuração via Terraform** |
| --- | --- | --- | --- |
| API de Inferência | Azure Container Apps | Traces (Latência), Métricas (RPS, Erro), Logs | Injeção do Connection String via secret na variável APPLICATIONINSIGHTS\_CONNECTION\_STRING |
| Azure ML Training | Azure ML Compute Cluster | Métricas de Experimento, Logs de Treinamento | Application Insights provisionado no módulo ML Platform. |
| Data Ingestion | Azure Data Factory / Event Hubs | Logs de Diagnóstico, Métricas de Vazão | Configuração de Log Analytics/App Insights via Private Link (se aplicável). |

**O Terraform, ao injetar a connection string via secret, garante que a aplicação esteja sempre instrumentada e isolada de mudanças na infraestrutura de monitoramento.**

---

## **Síntese e Conclusão: O Ciclo MLOps Reforçado pelo IaC**

O deployment de IA no Azure com Terraform estabelece uma arquitetura MLOps robusta, com governança, segurança e otimização de custos.

**Validação do Ciclo de Vida MLOps com Terraform.**

A estrutura modular com Terraform garante configurações uniformes entre produção e desenvolvimento, validando e aplicando a arquitetura MLOps.

**Auditoria de Segurança e Conformidade (Checklist IaC)**

A segurança é alcançada por múltiplos controles auditáveis via Terraform:

1. **Gerenciamento de Estado:** Acesso ao tfstate via Azure Active Directory ou Managed Identity.
    
2. **Perímetro de Rede:** Serviços críticos protegidos por Private Endpoints.
    
3. **Controle de Identidade:** Comunicação service-to-service via Managed Identity e RBAC.
    
4. **Ingestão de Dados:** Linked Services do ADF com autenticação Managed Identity.
    
5. **Governança:** Conformidade de tagging imposta via Azure Policy.
    

### **Próximos Passos e Expansão da Arquitetura**

O IaC deve expandir para gerenciar pipelines de treinamento no Azure ML, automatizar o Registro de Modelos e otimizar custos com redimensionamento de recursos via variáveis do Terraform.

---

## Referências citadas

Create workspaces by using Terraform - Azure Machine Learning - Microsoft Learn, [https://learn.microsoft.com/en-us/azure/machine-learning/how-to-manage-workspace-terraform?view=azureml-api-2](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-manage-workspace-terraform?view=azureml-api-2)

Backend Type: azurerm | Terraform - HashiCorp Developer, [https://developer.hashicorp.com/terraform/language/backend/azurerm](https://developer.hashicorp.com/terraform/language/backend/azurerm)

Guidelines for Organizing and Testing Your Terraform Configuration ..., [https://devblogs.microsoft.com/ise/terraform-structure-guidelines/](https://devblogs.microsoft.com/ise/terraform-structure-guidelines/) Azure/avm-res-machinelearningservices-workspace/azurerm |

Terraform Registry, [https://registry.terraform.io/modules/Azure/avm-res-machinelearningservices-workspace](https://registry.terraform.io/modules/Azure/avm-res-machinelearningservices-workspace)